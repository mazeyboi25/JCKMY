# 1. Differentiate Task and Data Parallelism. Identify which part of the lab demonstrates each and justify the workload division.
#### - Task Parallelism and Data Parallelism are different in how the work is divided. Task Parallelism separates the program into different operations that run at the same time on the same data. In the ThreadPoolExecutor code, each deduction (SSS, PhilHealth, Pag-IBIG, and Withholding Tax) is a separate function, but all of them use the same salary. The work is divided based on the type of task. On the other hand, Data Parallelism divides the work based on the data. In the ProcessPoolExecutor code, one payroll function is used, but it is applied to different employees at the same time. This means the same process is repeated for different data entries. Task Parallelism focuses on different functions, while Data Parallelism focuses on different data.

# 2. Explain how concurrent.futures managed execution, including submit(), map(), and Future objects. Discuss the purpose of with when creating an Executor.
#### - The concurrent.futures module controls how tasks are run in the background. The submit() function sends a task to be executed and immediately returns a Future object. A Future holds the result that will be produced later, and calling result() gets the final value once the task is done. In Data Parallelism, map() is used to apply one function to many data items automatically. The with statement is used to make sure the executor starts properly and shuts down correctly after finishing, so system resources are cleaned up safely.

# 3. Analyze ThreadPoolExecutor execution in relation to the GIL and CPU cores. Did true parallelism occur?
#### - Because of the Global Interpreter Lock (GIL) in Python, ThreadPoolExecutor does not create true parallelism for CPU-heavy tasks. Even if multiple threads are running, only one thread can execute Python code at a time. This means the tasks were running in turns, not truly at the same time on multiple CPU cores. Real parallelism happens when using ProcessPoolExecutor, because each process runs separately with its own Python interpreter, allowing multiple CPU cores to work at the same time.

# 4. Explain why ProcessPoolExecutor enables true parallelism, including memory space separation and GIL behavior.
#### - The ProcessPoolExecutor enables true parallelism because it creates separate processes, each with its own memory space and Python interpreter. Unlike threads, which are constrained by the Global Interpreter Lock (GIL) and cannot execute Python bytecode simultaneously, processes bypass this limitation. This separation allows multiple CPU cores to be utilized at the same time, ensuring that tasks can genuinely run in parallel. As a result, CPU-bound workloads benefit significantly from ProcessPoolExecutor , since it achieves real concurrency across cores rather than simulated parallelism through thread switching

# 5. Evaluate scalability if the system increases from 5 to 10,000 employees. Which approach scales better and why?
#### - When scaling from a small system with five employees to a large-scale system with 10,000 employees, the choice of executor becomes critical. The ThreadPoolExecutor is efficient for I/O-bound tasks, but for CPU-intensive operations such as payroll calculations, it is limited by the GIL, which prevents true parallel execution. This limitation makes it unsuitable for large-scale computation. On the other hand, the ProcessPoolExecutor scales better because it distributes tasks across multiple processes, each running independently on different CPU cores. Although process creation and communication introduce overhead, the ability to achieve true parallelism makes ProcessPoolExecutor the more effective approach for handling thousands of employees in a payroll system.

# 6. Provide a real-world payroll system example. Indicate where Task Parallelism and Data Parallelism would be applied, and which executor you would use.
#### - In a real-world payroll system, both task and data parallelism can be applied. Task parallelism would be used when calculating different deductions for a single employee, such as SSS, PhilHealth, Pag-IBIG, and withholding tax. These are distinct tasks that operate on the same salary data, and a ThreadPoolExecutor would be appropriate for managing them efficiently. Data parallelism, on the other hand, would be applied when processing payroll for thousands of employees, where the same payroll function is executed across multiple data entries. In this case, a ProcessPoolExecutor would be the better choice, as it allows the system to leverage multiple CPU cores to handle large datasets concurrently. By combining both approaches, a payroll system can achieve efficiency at both the individual employee level and across the entire workforce. 

